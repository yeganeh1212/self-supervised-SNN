%\alert{text}\clearpage
\phantomsection
%\addcontentsline{toc}{chapter}{مقدمات}
\chapter{شبکه‌های عصبی ضربه‌ای}
\markboth{ شبکه های عصبی ضربه‌ای}{عنوان فصل}
\section{الهام از روش یادگیری مغز}

 
در مغز انسان، فرآیند یادگیری و انتقال اطلاعات به شکلی بسیار پیچیده و اهمیت‌بخش اتفاق می‌افتد. سلول‌های عصبی که به نام نورون‌ها\LTRfootnote{\lr{Neuron}} نیز شناخته می‌شوند، از ساختاری حساس و پیچیده تشکیل شده‌اند. هر نورون دارای یک هسته مرکزی و تعدادی ترمینال ورودی است. در شبکه‌های عصبی مغز، وظیفه اصلی این نورون‌ها دریافت و پردازش اطلاعات می‌باشد. این اطلاعات به صورت پالس‌های الکتریکی با نام اسپایک‌ها\LTRfootnote{\lr{Spikes}} منتقل می‌شوند. وقتی پتانسیل یک نورون از آستانه‌ای تعیین شده عبور می‌کند، یک اسپایک الکتریکی تولید می‌شود که حاوی اطلاعات است. این اسپایک سپس به عنوان ورودی به نورون‌های بعدی انتقال داده می‌شود، و این فرآیند ادامه می‌یابد. مهم‌ترین ویژگی این اسپایک‌ها این است که به عنوان واحدهای انتقال اطلاعات عمل می‌کنند و نورون‌ها توسط این اسپایک‌ها با یکدیگر ارتباط برقرار می‌کنند.
 \citep{ponulak2011introduction}


 بیشتر نورون‌ها در شبکه مغز در حالت استراحت قرار دارند و تنها در صورتی که پتانسیل آن‌ها از حد آستانه‌ای تعیین شده عبور کند، اسپایک تولید می‌شود. این ویژگی باعث بهبود کارایی و مصرف انرژی در سیستم عصبی می‌شود. ساختار یک سلول عصبی شامل یک هسته مرکزی و تعدادی ترمینال ورودی است که وظیفه دریافت و انتقال اطلاعات را از نورون‌های قبلی به نورون‌های بعدی دارد. ساختار ساده شده یک سلول عصبی در شکل \ref{fig:neuron1}نمایش داده شده است .  
 \begin{figure}[htbp]
 	\centering
 	\includegraphics[width=9cm]{labeled-neurons-basics.png}
 	\caption{یک سلول عصبی با نمایش اجزا اصلی}
 	\label{fig:neuron1}
 \end{figure}
% \centerline{{\includegraphics[width=9 cm]{labeled-neurons-basics.png}}}
 
 نورون‌ها در شبکه مغز به وسیلهٔ درگاه اتصالی به نام سیناپس به یکدیگر متصل هستند و انتقال اطلاعات بین نورون‌ها به وسیلهٔ سیناپس \LTRfootnote{\lr{Synapse}} اتفاق می‌افتد. در صورتی که ولتاژ ورودی از سیناپس‌ها به حد مورد انتظار سلول برسد و پتانسیل سلول از آستانه عبور کند، سلول تحریک شده و یک اسپایک در ترمینال خروجی خود تولید می‌کند. به این سلول نورون پیش‌سیناپسی \LTRfootnote{\lr{Pre-synaptic neuron}} گفته می‌شود. این نورون اسپایک خروجی را در قالب یون‌های مثبت و منفی به صورت پالس‌های الکتریکی حاوی جریان به سیناپس‌های سلول‌های دیگر که به آن نورون پساسیناپسی \LTRfootnote{\lr{Post-synaptic neuron}} گفته می‌شود، منتقل می‌کند و به عنوان یک جریان وارد نورون می‌شود. در شکل \ref{fig:neuron2}، یک ساختار ساده‌شده از سیناپس و اتصال دو نورون پیش‌سیناپسی و پساسیناپسی نشان داده شده است.
   \citep{lein2016synaptic}
   
  \begin{figure}[htbp]
 	\centering
 	\includegraphics[width=9cm]{synaps_struct.png}
 	\caption{اتصال نورون فرستنده و گیرنده به وسیله سیناپس}
 	\label{fig:neuron2}
 \end{figure}
 
% \LTRfootnote{\lr{post-synaptic neuron}}
 
در این پایان‌نامه، قصد داریم یک شبکه عصبی اسپایکی الهام‌گرفته شده از ساختار شبکه مغز را پیاده‌سازی کنیم. همانطور که گفته شد، انتقال اطلاعات در مغز توسط اسپایک‌ها انجام می‌شود و نورون‌ها در بیشتر مواقع در حال استراحت هستند، به این معنا که خروجی اسپایکی ندارند. در راستای پیاده‌سازی شبکه الهام‌گرفته از مغز، در ابتدا به این دو مولفهٔ شبکه، یعنی اسپایک و پراکنده بودن\LTRfootnote{\lr{Sparsity}}، توجه می‌کنیم. در شکل \ref{fig:neuron3} نشان داده شده است که اگر یک الکترود را به نورون متصل کنیم، ساختار اسپایک خروجی همانند یک پالس الکتریکی است که در ساختار دادهٔ پراکنده ذخیره می‌شود.  \citep{wu2020training}
 \begin{figure}[htbp]
 	\centering
 	\includegraphics[width=12cm]{sparse.png}
 	\caption{خروجی اسپایکی نورون و خاصیت پراکندگی}
 	\label{fig:neuron3}
 \end{figure}
 
  اسپایک‌ها: سلول‌های عصبی زیستی اطلاعات را از طریق اسپایک‌ها (شاره‌های الکتریکی)منتقل می‌کنند که بیشترین ولتاژ  آنها حدود 100 میلی‌ولت است. در بسیاری از مدل‌های محاسباتی نورون‌ها این گسیل شدن ولتاژ را به یک رویداد گسسته و یک‌بیتی ساده تبدیل می‌کنند: '۱' یا '۰'. این نسخه ساده‌تر در سخت‌افزار نمایش دادن آن نسبت به یک مقدار با دقت بالا، بهترین کارایی را دارد.
  
  اسپایک‌ها: سلول‌های عصبی زیستی اطلاعات را از طریق اسپایک‌ها (شاره‌های الکتریکی) منتقل می‌کنند که بیشترین ولتاژ آن‌ها حدود 100 میلی‌ولت است. در بسیاری از مدل‌های محاسباتی نورون‌ها، این گسیل شدن ولتاژ را به یک رویداد گسسته و یک‌بیتی ساده تبدیل می‌کنند: '۱' یا '۰'. این نسخه ساده‌تر در سخت‌افزار نمایش دادن آن نسبت به یک مقدار با دقت بالا، بهترین کارایی را دارد.
  
  پراکندگی: نورون‌ها بیشتر زمان خود را در حال استراحت می‌گذرانند و اگر خروجی اسپایک را به عنوان عدد یک و زمان‌هایی که نورون خروجی ندارد را صفر در نظر بگیریم، بردارهای مربوط به خروجی نورون‌ها در طول زمان پراکنده‌گرا هستند؛ به این معنا که بیشتر عناصر این بردارها صفر است. این بردارها بسیار ساده و ارزان‌تر در ذخیره‌سازی هستند و برای بسیاری از محاسبات نیازی به خواندن بخش‌های صفر از حافظه نداریم که این خاصیت سرعت محاسبات را در این شبکه‌ها افزایش می‌دهد.
  
 یکی دیگر از مولفه‌های مهم شبکه‌های عصبی اسپایکی و وجه تمایز آن‌ها با دیگر شبکه‌های عصبی وجود مولفه زمان است. به این معنا که در شبکه‌های اسپایکی، تولید اسپایک در طول زمان اتفاق می‌افتد. برخلاف دیگر شبکه‌های عصبی مصنوعی که اطلاعات را در یک لحظه پردازش کرده و در همان لحظه خروجی را محاسبه می‌کند، شبکه‌های عصبی اسپایکی الهام گرفته شده از مغز اسپایک‌های ورودی خود را که خروجی نورون قبلی بوده، در طول گام‌های زمانی دریافت کرده و  هرزمان که پتانسیل آن به حد آستانه رسید اسپایک خروجی می‌د‌هد.
 
 در ادامه به بررسی جزئی تر این شبکه‌ها و ساختار داده ورودی و مدل‌های نورونی و نوع یادگیری در شبکه‌های عصبی اسپایکی می‌پردازیم.
 
\section{کد گذاری اسپایک‌های ورودی}

همان‌طور که اشاره شد، داده‌های ورودی و خروجی نورون‌ها از نوع اسپایک هستند و نورون‌ها به صورت پالس‌هایی با طول و مقدار یکسان خروجی تولید می‌کنند. در نتیجه، پالس‌ها در خود تفاوتی ندارند و لازم است اطلاعات در زمان ارسال این پالس‌ها ذخیره و کدگذاری شود. دو روش اصلی و مهم برای کدگذاری اسپایک وجود دارد که به توضیح آن‌ها می‌پردازیم:



\subsection{کد گذاری بر اساس نرخ اسپایک‌های تولید شده}
%اینجا متن زیربخش اول قرار می‌گیرد.
در این روش پردازش اطلاعات منتقل شده توسط نورون‌ها بر اساس تعداد یا فرکانس اسپایک‌های خروجی انجام می‌شود. به این معنا که هرچقدر تعداد اسپایک‌های خروجی از یک نورون بیشتر باشد، تأثیر آن نورون در شبکه بیشتر می‌شود و وزن بیشتری به آن اختصاص می‌یابد. این به این معناست که نورون فعالیت بیشتری دارد.

برای مثال، اگر فرض کنیم داده ورودی شبکه اسپایکی از نوع یک فریم عکس باشد، می‌توان برای کدگذاری هر فریم ورودی بر اساس نرخ اسپایک‌ها به صورت زیر عمل کرد:

اگر هر پیکسل با نرمال‌سازی را به عنوان احتمال رخداد یک اسپایک در نظر بگیریم که در یک گام زمانی به عنوان ورودی به شبکه داده شده است، می‌توان با استفاده از توزیع برنولی\LTRfootnote{\lr{Bernoulli distribution}} ورودی را بر اساس نرخ اسپایک‌ها کدگذاری کرد. معادله توزیع برنولی به صورت زیر است :
\begin{equation}
	P(X = x) = \begin{cases}
		p & \text{if } x = 1 \\
		1 - p & \text{if } x = 0
	\end{cases}
\end{equation}





% \begin{figure}[htbp]
%	\centering
%	\includegraphics[width=12cm]{ber2.png}
%	%\caption{خروجی اسپایکی نورون و خاصیت انکارانه‌گرایی}
%	%\label{fig:neuron3}
%\end{figure}

بر اساس شدت احتمال در هر پیکسل از داده ورودی با استفاده از توزیع برنولی می‌توان یک عدد به آن نسبت داد که برابر با نرخ اسپایک خروجی آن پیکسل خواهد شد.

در شکل  \ref{fig:neuron4}یک نمونه از پیکسل‌های مربوط به یک نمونه داده ورودی نشان داده شده است. بر اساس میزان شدت هر پیکسل و احتمال نسبت داده شده به آن می‌توان کدگذاری براساس نرخ اسپایک انجام داد. شکل\ref{fig:neuron5}

 \begin{figure}[htbp]
	\centering
	\includegraphics[width=5cm]{mnist1.png}
	\caption{یک نمونه از داده ورودی شبکه اسپایکی و تبدیل هر پیکسل از داده برای کدگذاری بر اساس نرخ اسپایک}
	\label{fig:neuron4}
\end{figure}

 \begin{figure}[htbp]
	\centering
	\includegraphics[width=5cm]{rate.png}
	\caption{ سه نوع از پیکسل های داده ورودی به عنوان نمونه و تبدیل آن ها به کدگذاری برا ساس نرخ اسپایک }
	\label{fig:neuron5}
\end{figure}

\subsection{کد گذاری بر اساس زمان اسپایک‌های تولید شده}
%اینجا متن زیربخش دوم قرار می‌گیرد.
در روش کدگذاری بر اساس زمان اسپایک میزان فعالیت نورون و وزن اهمیت آن در شبکه به زمان اولین اسپایک بستگی دارد و هرچه زمان اسپایک زدن نورون کوتاه تر باشد به معنای فعالیت بیشتر آن نورون است. در این مدل تنها اولین اسپایک خروجی از نورون اهمیت دارد و زمان آن به عنوان پارامتر اصلی فعالیت نورون در نظر گرفته میشود و باقی اسپایک ها اهمیتی ندارند. در شکل \ref{fig:neuron6} یک نمونه از کدگذاری براساس زمان نشان داده شده است 


\begin{figure}[htbp]
	\centering
	\includegraphics[width=5cm]{latency.png}
	\caption{ سه نوع از پیکسل های داده ورودی به عنوان نمونه و کدگذاری آن ها به اسپایک بر اساس زمان }
	\label{fig:neuron6}
\end{figure}

\section{مدلسازی نورون اسپایکی}

در این بخش به توضیح روش‌های مدلسازی نورون اسپایکی می‌پردازیم. در مدلسازی این نورون‌ها یک طیف گسترده از مدل‌های دقیق بیوفیزیک تا مدل‌هایی که نورون مصنوعی بسیار ساده را پیاده‌سازی کرده‌اند وجود دارد.
یک مدل نورونی که ویژگی های بسیار دقیق بیوفیزیکی را پیاده‌سازی کرده‌است مدل نورونی هاجکین-هاکسلی\LTRfootnote{\lr{Hodgkin-Huxley}} است. 
\citep{hodgkin1952quantitative}
اگرچه این  مدل‌های بیوفیزیکی می‌توانند نتایج الکتروفیزیولوژیکی را با دقت بسیار بالا تولید کنند، اما پیچیدگی آن‌ها باعث می‌شود که در حال حاضر استفاده از آن‌ها دشوار باشد.

 در طرف مقابل طیف نورون‌های مصنوعی وجود دارند 
که در آن‌ها ورودی‌ها با وزن‌های مربوطه ضرب می‌شوند و از طریق تابع فعال‌سازی عبور می‌کنند. این ساده‌سازی به محققان یادگیری عمیق اجازه داده‌است تا عملکردهای شگفت‌انگیزی در بینایی ماشین\LTRfootnote{\lr{Computer vision}}، پردازش زبان طبیعی \LTRfootnote{\lr{Natural Language Processing}}و بسیاری از وظایف دامنه‌های یادگیری ماشین دیگر انجام دهند.

 ما بین طیف مدلسازی‌های بیوفیزیکی و مدلسازی نورون‌های مصنوعی نوعی از مدل نورونی وجود دارد که تا حد ممکن به خواص بیوفیزیکی وفادار است و از طرفی پیچیدگی‌های محاسباتی آن در سطحی است که می‌توان به راحتی پیاده‌سازی کرد. نام این مدلسازی که در ادامه به توضیح آن می‌پردازیم مدل نورونی نشت کننده  و ادغام آتش\LTRfootnote{\lr{Leaky integrate-and-fire}} است.



\subsection{مدل نورونی نشت کننده  و ادغام آتش}
نوعی مدل نورون مشترک میان دو نوع مدل مصنوعی و هاجکین-هاکسلی، مدل نورون نشت‌کننده و ادغام‌ آتش \LTRfootnote{\lr{LIF}}است. این مدل  مانند نورون مصنوعی مجموع ورودی‌های وزن‌دار را می‌گیرد، اما به جای ارسال آن مستقیماً به تابع فعال‌سازی، ورودی را مانند یک مدار خازن مقاومت \LTRfootnote{\lr{Resistor and Capacitor circuit}}با یک نشتی زمانی ادغام می‌کند، اگر مقدار ادغام‌شده از مقدار پتانسیل آستانه نورون عبور کند  نورون LIF یک اسپایک از جنس پالس الکتریکی ایجاد می‌کند. 

نورون LIF در میان واقعیت زیستی و کاربرد‌پذیری قرار می‌گیرد و هم سعی می‌کند خاصیت های بیوفیزیک نورون را شبیه سازی کند و هم قابلیت پیاده سازی داشته باشد.مدلسازی نورون‌های LIF با توجه به ساختار نورون‌های مغز اتفاق می‌افتد. نورون‌های مغز مانند تمام سلول‌ها توسط یک غشای نازک احاطه شده است. این غشاء یک لایه‌دهی لیپیدی است که داخل نورون را از محیط خارجی جدا می‌کند. از نظر الکتریکی، این غشا مانند ک خازن عمل می‌کند که دارای یک ظرفیت خاص می‌باشد. در شبیه سازی نورون‌های اسپایکی هدف محاسبه تغییرات پتانسیل غشا در طول زمان است که در این نوع شبیه سازی به عنوان یک خازن در نظر گرفته می‌شود. با محاسبه تغییرات پتانسیل و مشخص کردن آستانه و در نتیجه گسیل کردن اسپایک می‌توان عملکرد یک نورون اسپایکی را مدلسازی کرد. به این صورت که با محاسبه تغییرات پتانسیل در طول زمان اگر پتانسیل نورون از آستانه خود عبور کند (مانند خازنی که ظرفیت آن پر شده و تخلیه می‌شود.)نورون یک اسپایک گسیل می‌کند و پتانسیل آن به حالت استراحت باز می‌گردد و این فرایند دوباره تکرار می‌شود.
\citep{moreno2006auto}

یکی دیگر از وظایف این غشاء، کنترل آنچه که به داخل و خارج از این سلول می‌رود است. این غشاء به طور معمول نسبت به یون‌ها نفوذناپذیر است و مانع ورود و خروج آن‌ها از بدنه نورون می‌شود. اما در غشاء کانال‌های مشخصی وجود دارند که با تزریق جریان به نورون، فعال می‌شوند. این جابجایی بار به طور الکتریکی توسط یک مقاومت مدلسازی می‌شود.
با توجه به توضیحات داده شده یک نورن LIF توسط یک مدار دارای یک خازن که نقش غشا نورون را دارد  و یک مقاومت برای مدلسازی کانال های غشا نورون پیاده سازی می‌شود. در شکل \ref{fig:neuron7}شبیه سازی غشا نورونی به مدار RC نشان داده شده است.

\begin{figure}[htbp]
	\centering
	\includegraphics[width=9cm]{rc.png}
	\captionsetup{font=small} % Adjust the font size of the caption
	\caption{ شبیه سازی غشا لیپیدی یک نورون به یک مدار خازن مقاومت الکتریکی.غشا دولایه مانند یک خازن رفتار می‌کند که پتانسیل آن نقش ظرفیت خازن را دارد. غشا نورون دارای کانال‌های یونی برای انتقال یون‌ها به نورون می‌باشد که رفتار آن مشابه مقاومت در مدار است.}
	\label{fig:neuron7}
\end{figure}

برای مدلسازی ریاضی نورون LIF ابتدا از حل معادله دیفرانسیل مربوط به تغییرات پتانسیل غشا در طول زمان آغاز می‌کنیم:

%\begin{figure}[h]
%	\centering
%	\includegraphics[width=7cm]{eq1.png}
%	%\caption{}
%	%\label{}
%\end{figure}

%\begin{minipage}{\linewidth}
%	\centering
%	\includegraphics[width=0.5\linewidth]{eq1.png}
%\end{minipage}

\begin{equation}
	\tau_m \frac{{dU(t)}}{{dt}} = -(U(t) - U_{rest}) + R \cdot I_{in}(t)
\end{equation}

\begin{align}
%	\tau_m \frac{{dU}}{{dt}} &= -(U - U_{rest}) + R \cdot I(t) \\
	\text{که در این معادله:} \nonumber \\
	\tau_m &: \text{ثابت زمانی برای پتانسیل غشا سلول} \nonumber \\
	U(t) &: \text{پتانسیل غشا سلول} \nonumber \\
	U_{rest} &: \text{پتانسیل غشا در حال استراحت} \nonumber \\
	R &: \text{مقاومت} \nonumber \\
	I(t) &: \text{جریان تابع زمان} \nonumber
\end{align}


 پاسخ کلی معادله دیفرانسیل غشا به صورت زیر خواهد شد :
 \begin{equation}
U(t) = U_{rest} + (U(0) - U_{rest}) \cdot e^{-\frac{t}{\tau_m}} + \frac{R}{\tau_m} \int_{0}^{t} e^{-\frac{t - s}{\tau_m}} \cdot I_{in}(s) \, ds
 \end{equation}
 
 
 
 
% \begin{figure}[h]
% 	\centering
% 	\includegraphics[width=8cm]{eq2.png}
% \end{figure}
% 
 
با حل تحلیلی معادله دیفرانسیل یک راه حل برای بدست آوردن مقدار پتانسیل غشا در طول زمان بدست آمد اما برای اینکه بتوانیم از این مفهوم در یادگیری شبکه‌های عصبی استفاده کنیم باید یک فرم گسسته و بازگشتی از معادله را بازسازی کنیم. برای این کار از روش اویلر برای حل معادلات دیفرانسیل استفاده می‌کنیم و این فرم را می‌توانیم مستقیم در روند یادگیری شبکه عصبی اسپایکی به کار بریم.
 
فرم گسسته شده معادله دیفرانسیل به صورت زیر نوشته می‌شود :
 \begin{equation}
U[t+1] = U[t] + \frac{1}{\tau_m} \left( - (U[t] - U_{rest}) + R \cdot I_{in}[t] \right) \Delta t
 \end{equation}

% \begin{equation}
%u(t) = I_{in}(t)R + [u_0 - I_{in}(t)R] e^{-\frac{t}{\tau}}
% \end{equation}
% \begin{figure}[h]
%	\centering
%	\includegraphics[width=12cm]{eq3.png}
%\end{figure}
  
  اگر بازه زمانی یک مقدار گسسته بسیار کوچک در نظر گرفت معادله را به روش اویلر می‌توان به صورت زیر بازنویسی کرد :
  \begin{equation}
  	u(t + \delta t) = u(t) + \delta t \left( -\frac{1}{\tau} \cdot (u(t) - u_{\text{rest}}) + I_{\text{in}}(t) \cdot R \right)
  \end{equation}
%  \begin{figure}[h]
%  	\centering
%  	\includegraphics[width=9cm]{eq4.png}
%  \end{figure}
  
  با حل این معادله در گام‌های زمانی و با مقدار اولیه U=0.9v  و جریان ورودی صفر شکل  \ref{fig:neuron8}تغییرات پتانسیل را در طول زمان نشان می‌دهد. همانطور که در شکل مشخص است پتانسیل غشا از یک مقدار اولیه آغاز شده و در طول زمان به صورت نمایی افت کرده است.در این حالت فرض کردیم که جریانی به غشا وارد نشده است.
  \begin{figure}[h]
  	\centering
  	\includegraphics[width=9cm]{pot.png}
  	\captionsetup{font=small} % Adjust the font size of the caption
  	\caption{شبیه سازی معادله دیفرانسیل گسسته سازی شده مربوط به تغییرات پتانسیل غشا در طول زمان بدون جریان ورودی}
  	\label{fig:neuron8}
  \end{figure}
  
  حال اگر بخواهیم مقدار جریان اولیه را به عنوان ورودی به نورون که در این شبیه سازی نقش خازن در مدار را دارد اضافه کنیم و اگر فرض کنیم پتانسیل از مقدارا اولیه برابر با صفر شروع خواهد شد و مقدار جریان ورودی برابر با 100mA است تغییرات پتانسیل شبیه سازی‌شده در گام‌های زمانی در شکل \ref{fig:neuron9} نشان داده شده است.
   \begin{figure}[htbp]
  	\centering
  	\includegraphics[width=9cm]{pot2.png}
  	\captionsetup{font=small} % Adjust the font size of the caption
  	\caption{شبیه سازی معادله دیفرانسیل گسسته سازی شده مربوط به تغییرات پتانسیل غشا در طول  زمان با جریان ورودی ثابت}
  	\label{fig:neuron9}
  \end{figure}
% در مرحله بعد اگر فرض کنیم جریان در یک گام زمانی وصل و سپس قطع می‌شود تغییرات پتانسیل به صورت زیر خواهد بود :
% 
% 
% اگر زمان پالس جریان را بسیار کوتاه کنیم به صورتی که همانند اسپایک در یک لحظه اتفاق بیافتد می‌توان معادله جریان را به صورت یک دلتای دیراک نوشت :
% 

% در این مرحله شبیه سازی نشتی پتانسیل به حالت استراحت و ادغام جریان از مدل نورونی نشت کننده و ادغام آتش انجام شده است. در مرحله بعد به سراغ شبیه سازی قسمت آتش می‌رویم.
 همانطور که گفته شد نورون‌ها اسپایک را به عنوان ورودی می‌گیرند و برای اینکه اسپایک گسیل کنند باید مقدار پتانسیل آن‌ها از یک آستانه عبور کند در این صورت نورون یک اسپایک گسیل کرده و پتانسیل به حالت استراحت باز‌می‌گردد.
شکل \ref{fig:neuron10}یک شبیه سازی اولیه از پتانسیل یک نورون مدل شده به وسیله مکانیسم نشت کننده و ادغام آتش است :
 
  \begin{figure}[htbp]
 	\centering
 	\includegraphics[width=9cm]{pot3.png}
 	\captionsetup{font=small} % Adjust the font size of the caption
 	\caption{تغییرات پتانسیل غشا در طول  زمان با جریان ورودی ثابت با در نظر گرفتن مکانیسم نشت کننده و ادغام آتش }
 	\label{fig:neuron10}
 \end{figure}
 
 همانطور که مشاهده می‌شود در ابتدا یک جریان ثابت به نورون وارد شده پتانسیل آن شروع به افزایش کرده و هنگامی که به آستانه رسیده یک اسپایک گسیل کرده و سپس پتانسیل به حالت استراحت نشت کرده است.
 
 
 
 در این مرحله می‌توانیم از مدل نورونی ساخته‌شده در یک شبکه عصبی استفاده کنیم.
 

\section{شبکه عصبی ضربه‌ای }


همانطور که گفته شد برای استفاده از مدل نورونی نشت کننده و ادغام آتش در شبکه‌های عصبی باید یک فرم بازگشتی گسسته از معادله دیفرانسیل ارائه دهیم :

اگر بتا را به عنوان نرخ کاهش پتانسیل غشا در نظر بگیریم :

\begin{equation}
	\beta = 1 - \frac{1}{\tau}
\end{equation}

\begin{equation}
	U[t + 1] = \beta  \cdot U[t] + (1 - \beta)I_{in}[t+1]
\end{equation}
%
%\begin{minipage}{\linewidth}
%	\centering
%	\includegraphics[width=0.6\linewidth]{eq5.png}
%\end{minipage}

در یادگیری عمیق پارامتر‌های وزن معمولا در طول فرایند یادگیری آموزش داده می‌شوند. در این مرحله جریان ورودی را به دو بخش که یک پخش آن پارامتر ورودی شبکه است و بخش دیگر یک پارامتر قابل یادگیری است جداسازی می‌کنیم:


\begin{equation}
	WX[t] = I_{in}[t]
\end{equation}

%
%\begin{minipage}{\linewidth}
%	\centering
%	\includegraphics[width=0.2\linewidth]{w.png}
%\end{minipage}
%


در این صورت پارامتر ورودی مربوط به جریان را می‌توان همان اسپایک وارد شده به نورون در نظر گرفت. برای اسپایک ورودی به نورون باید یک تابع تعریف کنیم که تغییرات پتانسیل را نیز نشان دهد تابع را به صورت زیر تعریف می‌کنیم:

\begin{equation}
	\text{S}_{\text{out}}[t] = 
	\begin{cases}
		1, & \text{if } U[t] \geq {\theta} \\
		0, & \text{otherwise}
	\end{cases}
\end{equation}

%\begin{minipage}{\linewidth}
%	\centering
%	\includegraphics[width=0.3\linewidth]{spk.png}
%\end{minipage}

در نتیجه تغییرات پتانسیل را به صورت معادله زیر بازنویسی می‌کنیم:

\begin{equation}
U[t] = \underset{\text{decay}}{\beta U[t-1]} + \underset{\text{input}}{WX[t]} - \underset{\text{reset}}{S_{out}[t-1] \cdot \theta}
\end{equation}


%\begin{minipage}{\linewidth}
%	\centering
%	\includegraphics[width=0.4\linewidth]{eq66.png}
%\end{minipage}

این معادله را می‌توان مستقیم در شبکه عصبی به کار برد. 

%در شکل زیر یک نمونه از شکل شبکه عصبی اسپایکی ۳ لایه را مشاهده می‌کنیم:

همانطور که گفته شد داده ورودی در شبکه‌های اسپایکی باید دارای پارامتر زمان باشد در نتیجه اگر داده در زمان یک ساختار ثابت دارد آن را به صورت یک جریان ثابت به عنوان ورودی در چند گام زمانی 
به شبکه می‌دهیم و فعالیت نورون و تغییرات پتانسیل آن و همچنین اسپایک‌های خروجی از نورون را به عنوان خروجی مشاهده و بررسی می‌کنیم. در نتیجه خروجی شبکه اسپایکی هموراه یک بعد زمان خواهد داشت.


\subsection{ یادگیری در شبکه های عصبی ضربه‌ای}

برای استفاده از مدل نورونی اسپایکی نشت کننده و ادغام آتش در شبکه‌های عصبی یک فرم بازگشتی گسسته از تغییرات پتانسیل نورون بازسازی کردیم. در این معادله یک تابع برای گسیل اسپایک در نظر گرفته شد. در شکل \ref{fig:neuron11}نحوه عملکرد تابع تعریف شده برای گسیل اسپایک نمایش داده شده است .

 \begin{figure}[htbp]
	\centering
	\includegraphics[width=6cm]{spk2.png}
	\captionsetup{font=small} % Adjust the font size of the caption
	\caption{تابع تعریف شده برای فرآیند گسیل اسپایک توسط نورون }
	\label{fig:neuron11}
\end{figure}

همانطور که می‌دانیم یادگیری در شبکه‌های عصبی به وسیله کمینه کردن مشتق زنجیره‌ای توابع اتفاق می‌افتد. در این مساله تابع تعریف شده برای گسیل اسپایک مشتق پذیر نیست در شکل\ref{fig:neuron12}فرآیند مشتق گیری و مساله تابع گسیل اسپایک نشان داده شده‌است. همانطور که مشاهده می‌کنیم که تابع گسیل اسپایک همانند  تابع دلتای دیراک\LTRfootnote{\lr{Delta Dirac function}} است که هموراه برابر با صفر است به جز مواقع رد کردن آستانه پتانسیل نورون که به بینهایت میل می‌کند که به این معناست که گرادیان قابل محاسبه نیست و فرایند یادگیری به درستی اتفاق نمی‌افتد. به این مساله در مدلسازی نورون‌های اسپایکی مساله نورون مرده \LTRfootnote{\lr{Dead neuron problem}} می‌گویند.
برای حل این مساله و پیاده‌سازی یادگیری در شبکه‌های عصبی اسپایکی روش‌های مختلفی استفاده می‌شود . یکی از روش‌های مرسوم استفاده از یک تابع جایگزین است که در بخش بعد به توضیح آن می‌پردازیم.

\begin{figure}[htbp]
	\centering
	\includegraphics[width=7cm]{spk3.png}
	\captionsetup{font=small} % Adjust the font size of the caption
	\caption{فرایند مشتق گیری زنجیره ‌ای در یادگیری شبکه عصبی و مساله مشتق پذیر نبودن تابع تعریف شده برای گسیل اسپایک }
	\label{fig:neuron12}
\end{figure}



\subsection{روش گرادیان جایگزین در شبکه های عصبی ضربه‌ای}

همانطور که گفته‌شد تابع گسیل اسپایک یک تابع پله است که گرادیان آن به صورت یک تابع دلتای دیراک بدست ‌می‌آید که فریاند مشتق پذیری در یادگیری برای کمینه کردن وزن‌ها را مختل می‌کند. یک راه حل برای این مساله استفاده از یک تابع مشتق پذیر با عملکرد مشابه تابع اصلی می‌باشد که این روش را گرادیان جایگزین می‌نامیم. \LTRfootnote{\lr{Surrogate gradient discent}}
یکی از توابع مورد استفاده برای جایگزین کردن تابع اصلی گسیل اسپایک تابع سیگموید \LTRfootnote{\lr{Sigmoid function}}است. در شکل \ref{fig:neuron13}فرایند گرادیان گیری تابع سیگموید و عملکرد آن قابل مشاهده است.

\begin{figure}[htbp]
	\centering
	\includegraphics[width=6cm]{sur.png}
	\captionsetup{font=small} % Adjust the font size of the caption
	\caption{تابع جایگزین برای حل مساله مشتق پذیر نبودن تابع گسیل اسپایک}
	\label{fig:neuron13}
\end{figure}


به وسیله جایگزین کردن این تابع با تابع اصلی فرایند یادگیری و کمینه کردن وزن‌ها در شبکه به درستی اتفاق می‌افتد و می‌توان از شبکه عصبی اسپایکی ساخته شده در مسائل یادگیری ماشین استفاده کرد.







%\section{داده های نورومورفیک}